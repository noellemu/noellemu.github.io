[{"title":"【LeetCode HOT 100】19. Remove Nth Node From End of List","url":"/554b45c19de4/","content":"\n## 题目地址\n\n[19. Remove Nth Node From End of List](https://leetcode.cn/problems/remove-nth-node-from-end-of-list/)\n\n## 解题方法\n\n看到链表第一反应：双指针。\n\n求链表长度等比较简单的方法就不讲了，这里讲一下最优解（双指针）。\n\n这道题如果是一个有头结点的链表，那么能简化很多代码，我们可以给链表手动添加一个头结点 `dummy`。初始情况下快指针 `f` 指向第一个结点 `head`，慢指针 `s` 指向头结点 `dummy`。由于需要求倒数第 n 个结点，那么可以让快指针 `f` 先走 n 步，然后快慢指针一起走，直到 `f` 越界为止，此时 `s` 指向的就是倒数第 `n` 个结点的前一个结点，直接把 `s` 的下一个结点从链表中摘除（`s.Next = s.Next.Next`）即可。注意最后需要返回 `dummy.Next`，否则链表中只有一个结点的情况会 WA（也可以使用 `head.Next == nil` 特殊判断一下）。\n\n## 复杂度分析\n\n时间复杂度：O(n)，需要完整遍历一次链表。\n\n空间复杂度：O(1)，只使用了常数个数的存储空间。\n\n## AC 代码\n\n```go\n/**\n * Definition for singly-linked list.\n * type ListNode struct {\n *     Val int\n *     Next *ListNode\n * }\n */\nfunc removeNthFromEnd(head *ListNode, n int) *ListNode {\n    dummy := &ListNode{Val: -1, Next: head}\n    f, s := head, dummy\n    for i := 0; i < n; i++ {\n        f = f.Next\n    }\n    for f != nil {\n        f = f.Next\n        s = s.Next\n    }\n    s.Next = s.Next.Next\n\n    return dummy.Next\n}\n```\n","tags":["Algorithm","Two Pointers","Linked List"],"categories":["Algorithm","LeetCode"]},{"title":"【LeetCode HOT 100】11. Container With Most Water","url":"/4b76ec1a08c6/","content":"\n## 题目地址\n\n[11. Container With Most Water](https://leetcode.cn/problems/container-with-most-water/)\n\n## 解题方法\n\n不难想到我们每次都需要向内移动两侧的板来计算可能达到的最大容量，并且在这个移动过程中维护最大容量，那么如何移动就成了一个问题。如果想让容量尽可能的大，那么我们就需要每次都移动两侧较短的板（如果长度相同的话则移动哪个都可以），直到容器的宽度为 0，这样问题就转换为了一个很简单的双指针问题。\n\n个人认为其实这道题与其说是考察什么算法，不如说是一道博弈论的题目。\n\n## 复杂度分析\n\n时间复杂度：O(n)，需要遍历数组一次。\n\n空间复杂度：O(1)，只使用了常数个数的存储空间。\n\n## AC 代码\n\n```go\nfunc maxArea(height []int) int {\n    maxAmount := 0\n    l, r := 0, len(height)-1\n    for l < r {\n        // 求出两侧较短的板的高度\n        h := height[l]\n        if height[l] > height[r] {\n            h = height[r]\n        }\n        // 求出此时容器的容量，并维护最大容量\n        amount := (r - l) * h\n        if amount > maxAmount {\n            maxAmount = amount\n        }\n        // 移动较短的一侧\n        if height[l] < height[r] {\n            l++\n        } else {\n            r--\n        }\n    }\n    return maxAmount\n}\n```\n","tags":["Algorithm","Two Pointers"],"categories":["Algorithm","LeetCode"]},{"title":"【LeetCode HOT 100】5. Longest Palindromic Substring","url":"/015299e0586e/","content":"\n## 题目地址\n\n[5. Longest Palindromic Substring](https://leetcode.cn/problems/longest-palindromic-substring/)\n\n## 解题方法\n\n这道题其实也是一道动态规划的题目，并且使用的是一种比较特殊的方法：中心扩展算法。\n\n一个字符串是回文串的条件如下：\n\n1. 串长为 1 时，该字符串是回文串。\n2. 串长为 2 时，如果该字符串的两个字符相同，则该字符串是回文串。\n3. 串长大于等于 3 时，如果该字符串去掉头尾两个字符仍然是回文串，那么该字符串是回文串。\n\n据此可以推导出状态转换方程：\n\n- `dp[i][i] = true`\n- `dp[i][i+1] = (s[i] == s[i+1])`\n- `dp[i][j] = dp[i+1][j-1] && s[i] == s[j]`\n\n根据状态转换方程可以得到表达式 `if s[i] == s[j] && (j-i<=2 || dp[i+1][j-1]) { /* s[i][j] 是回文串 */ }`，因为无论有几个字符，回文串的第一个字符和最后一个字符一定都是相同的（也就是 `s[l] == s[r]`），可以提出来当作公共条件。根据这个表达式依次计算并维护最长回文串的长度和边界即可。\n\n## 复杂度分析\n\n时间复杂度：O(n^2)，需要遍历数组 n ^ 2 次。\n\n空间复杂度：O(n^2)，需要一个 n * n 的 DP 数组辅助计算。\n\n## AC 代码\n\n```go\nfunc longestPalindrome(s string) string {\n    if len(s) < 2 {\n        return s\n    }\n    n := len(s)\n    maxL, maxR := 0, 0\n    maxLen := 0\n    // 构造一个 n * n 的数组暂存结果\n    dp := make([][]bool, n)\n    for i := 0; i < n; i++ {\n        dp[i] = make([]bool, n)\n    }\n    // 初始状态：l = r 时，dp[l][r] = true\n    // 状态转移方程：当 s[l] = s[r] 且 l - r < 2（子串只有两个以下字符）或 dp[l+1][r-1] = true 时，dp[l][r] = true\n    for r := 1; r < len(s); r++ {\n        for l := 0; l < r; l++ {\n            if s[l] == s[r] && (r-l<=2 || dp[l+1][r-1]) {\n                dp[l][r] = true\n                if r - l + 1 > maxLen {\n                    maxLen = r - l + 1\n                    maxL, maxR = l, r\n                }\n            }\n        }\n    }\n    // 注意 Golang 的截取操作为左闭右开\n    return s[maxL:maxR+1]\n}\n```\n","tags":["Algorithm","Dynamic Programming (DP)"],"categories":["Algorithm","LeetCode"]},{"title":"【LeetCode HOT 100】3. Longest Substring Without Repeating Characters","url":"/50d286f3428f/","content":"\n## 题目地址\n\n[3. Longest Substring Without Repeating Characters](https://leetcode.cn/problems/longest-substring-without-repeating-characters/)\n\n## 解题方法\n\n这道题可以说是滑窗的入门题了。\n\n用 `l` 和 `r` 两个变量规定滑窗的左右两端，`l` 每次循环前进一个字符，并把离开滑窗的字符 `s[l-1]` 从滑窗中移除。`l` 前进完毕后，开始尝试扩张滑窗：`r` 每次前进一个字符，并把进入滑窗的字符 `s[r]` 添加到哈希表中，直到 `r` 越界或 `s[r]` 在哈希表中出现时，停止扩张，计算滑窗长度 `r - l` 并更新滑窗的最大长度 `ans`，最后返回 `ans` 即可。\n\n## 复杂度分析\n\n时间复杂度：O(n)，需要将 `s` 遍历一次。\n\n空间复杂度：O(|∑|)，题目规定“s consists of English letters, digits, symbols and spaces”，即 ASCII 字符集，因此可以认为最坏情况为 ASCII 字符集中的所有字符都出现在滑窗中，所以 ∑ 为 ASCII 字符集的长度，即 `128`。\n\n## AC 代码\n\n```go\nfunc lengthOfLongestSubstring(s string) int {\n    m := make(map[byte]bool)\n    ans, r := 0, 0\n    for l := 0; l < len(s); l++ {\n        // 从哈希表里删除离开滑窗的字符\n        if l > 0 {\n            delete(m, s[l-1])\n        }\n        // 开始尝试向右扩张滑窗，直到越界或遇到滑窗中已有的字符\n        // 每次将一个字符纳入滑窗，都将它放入哈希表中\n        for ; r < len(s) && !m[s[r]]; r++ {\n            m[s[r]] = true\n        }\n        // 向右扩张完毕，计算出滑窗当前的长度 r - l，并与最大值比较\n        if r - l > ans {\n            ans = r - l\n        }\n    }\n    return ans\n}\n```\n","tags":["Algorithm","Hash Map","Sliding Window Algorithm"],"categories":["Algorithm","LeetCode"]},{"title":"【LeetCode HOT 100】2. Add Two Numbers","url":"/f37957f67304/","content":"\n## 题目地址\n\n[2. Add Two Numbers](https://leetcode.cn/problems/add-two-numbers/)\n\n## 解题方法\n\n这道题比较简单，使用一个变量 `carry` 记录进位信息，然后边遍历边相加边判断进位即可，结果可以写入一个新的链表 `ans`。\n\n设 `l1` 当前遍历到的结点为 `p1`，`l2` 当前遍历到的结点为 `p2`，则 `carry` 为：`(p1.Val + p2.Val) / 10`，`ans` 链表该位置上的结点 `p` 的值为 `(p1.Val + p2.Val) % 10`。\n\n当较短的链表遍历完成之后，对于较长的链表，可以有以下两种处理方法：\n\n1. 分情况讨论，对较长的链表继续与 `carry` 执行相加操作，比较容易想到但是代码比较复杂。\n2. 在较短的链表后面补 0（`p1` 或 `p2` 为 `nil` 时，将这个结点的值视为 `0`）并使用短链表没有遍历完成时的相加逻辑（代码比较简单）。\n\n两个链表都遍历完成之后，如果 `carry == 1`，则需要在 `ans` 的最后补上一个 `1`。\n\n## 复杂度分析\n\n时间复杂度：O(max(m, n))，其中 m，n 为两个链表的长度。\n\n空间复杂度：O(1)，除返回值外只使用了常数个数的空间。\n\n## AC 代码\n\n分类讨论：\n\n```go\n/**\n * Definition for singly-linked list.\n * type ListNode struct {\n *     Val int\n *     Next *ListNode\n * }\n */\nfunc addTwoNumbers(l1 *ListNode, l2 *ListNode) *ListNode {\n    carry := 0\n    p1, p2 := l1, l2\n    ans := &ListNode{Val: 0, Next: nil}\n    p := ans\n    for ; p1 != nil && p2 != nil; p1, p2 = p1.Next, p2.Next {\n        val := p1.Val + p2.Val + carry\n        carry = val / 10\n        val %= 10\n        node := &ListNode{Val: val, Next: nil}\n        p.Next = node\n        p = p.Next\n    }\n    for ; p1 != nil; p1 = p1.Next {\n        val := p1.Val + carry\n        carry = val / 10\n        val %= 10\n        node := &ListNode{Val: val, Next: nil}\n        p.Next = node\n        p = p.Next\n    }\n    for ; p2 != nil; p2 = p2.Next {\n        val := p2.Val + carry\n        carry = val / 10\n        val %= 10\n        node := &ListNode{Val: val, Next: nil}\n        p.Next = node\n        p = p.Next\n    }\n    if carry == 1 {\n        p.Next = &ListNode{Val: 1, Next: nil}\n    }\n    return ans.Next\n}\n```\n\n补 0:\n\n```go\n/**\n * Definition for singly-linked list.\n * type ListNode struct {\n *     Val int\n *     Next *ListNode\n * }\n */\nfunc addTwoNumbers(l1 *ListNode, l2 *ListNode) *ListNode {\n    carry := 0\n    p1, p2 := l1, l2\n    ans := &ListNode{Val: 0, Next: nil}\n    p := ans\n    for p1 != nil || p2 != nil {\n        val1, val2 := 0, 0\n        if p1 != nil {\n            val1 = p1.Val\n        }\n        if p2 != nil {\n            val2 = p2.Val\n        }\n\n        val := val1 + val2 + carry\n        carry = val / 10\n        val %= 10\n        node := &ListNode{Val: val, Next: nil}\n        p.Next = node\n        p = p.Next\n\n        if p1 != nil {\n            p1 = p1.Next\n        }\n        if p2 != nil {\n            p2 = p2.Next\n        }\n    }\n    if carry == 1 {\n        p.Next = &ListNode{Val: 1, Next: nil}\n    }\n    return ans.Next\n}\n```\n","tags":["Algorithm","Linked List"],"categories":["Algorithm","LeetCode"]},{"title":"【LeetCode HOT 100】1. Two Sum","url":"/2e76cd4c5980/","content":"\n## 题目地址\n\n[1. Two Sum](https://leetcode.cn/problems/two-sum/)\n\n## 解题方法\n\n这道题也是老熟人了，我感觉我至少做过五遍。\n\n暴力解法（时间复杂度 `O(n^2)`）大家应该都知道，那就来讲讲非暴力解法吧。\n\n我们可以用一个哈希表 `m` 保存 `nums` 中的元素与下标的对应关系，由于一个数字只能使用一次，因此我们遍历 `nums` 数组，每次都查找 `target` 与当前元素 `num` 的差值是否在哈希表中。如果在，则说明 `m[target-num] + num = target`，返回 `m[target-num]` 和 `num` 的下标 `i1`；如果不在，则将 `num` 及其下标添加到哈希表中（即 `m[num] = i1`）。\n\n## 复杂度分析\n\n时间复杂度：O(n)，需要遍历一次数组。\n\n空间复杂度：O(n)，哈希表占用的内存空间与 `nums` 的长度相关。\n\n## AC 代码\n\n```go\nfunc twoSum(nums []int, target int) []int {\n     m := make(map[int]int)\n    for i, num := range nums {\n        if i1, ok := m[target-num]; !ok {\n            m[num] = i\n        } else {\n            return []int{i1, i}\n        }\n    }\n    return []int{0, 0}\n}\n```\n","tags":["Algorithm","Hash Map"],"categories":["Algorithm","LeetCode"]},{"title":"记一次缓存引起的数据异常 Bug 的排查过程","url":"/8f438e4dddfd/","content":"\n## 背景\n\n在我工作中开发的一个类似于 `Ansible` 和 `蓝鲸作业平台` 的作业平台中，由于 `MongoDB` 性能瓶颈导致 `NSQ` 消息队列积压严重，经讨论后决定将作业执行过程中的作业状态转换、作业日志存储等逻辑从直接读写 `MongoDB` 重构为基于 `sync.Map` 自行实现的进程内缓存——将作业数据以作业 ID 为 `key`，作业数据为 `value` 保存在 `sync.Map` 中（这个方案并不怎么好，后文会提到优化方案），并且启动了几个定时任务将 `sync.Map` 中的数据每隔 10 秒对执行中的作业执行历史数据进行落库操作。作业中所有步骤的执行历史信息在作业执行开始或跳过失败步骤时写入缓存和数据库，此后会进入一个类似 `Event Loop` 的无限 `for` 循环，每次循环都会根据作业执行目标的数量和状态判断作业的状态，若已成功结束（成功目标总数 `Succeed` = 执行目标总数 `Total`）则会立即发送下一个步骤给执行目标。\n\n这样一来，业务逻辑就发生了变化：\n\n- 优化前：作业执行消息到来 - 从 DB 中加载作业执行历史数据（主要是成功 / 失败 / 执行中三种状态的主机数量、重做次数等） - 根据执行历史数据和消息内容判断作业的状态 - 将状态和日志信息写入 DB。\n- 优化后：作业执行消息到来 - 从缓存中加载作业执行历史数据（未命中缓存则查 DB）- 根据消息内容判断作业的状态 - 将状态和日志信息写入缓存 - 通过定时任务将作业执行历史信息落库（如果作业执行已经结束，则立即落库，降低资源消耗）。\n\n显而易见的是，这种机制是 `Cache Aside`（先查缓存，缓存未命中则查数据库，修改时先写 DB 再写缓存）和 `Read Through / Write Behind`（写操作直接写缓存，然后由定时任务同步到 DB） 的结合体。\n\n但在某一天，出现了一个诡异的恶性 Bug：当作业的第一个步骤执行失败时，对这个步骤执行跳过操作，之后的所有步骤都会不经执行而直接被设为成功。若查看作业执行历史，会发现步骤实际上执行了，日志也成功返回到服务端。此外，该 Bug 是随机发生的，在触发条件未知的情况下无法 100% 复现。\n\n由于这个 Bug 与步骤和作业的状态判断逻辑有关，可能会引发严重的问题，于是立即展开排查与修复工作。\n\n## 问题表现\n\n- 该 Bug 是随机发生的，在不知晓原因的情况下无法 100% 复现。\n- 必须有一个步骤（可以是第一步、第二步……第 n 步）失败并且对这个步骤执行跳过操作才有可能发生。\n- 从作业执行开始到执行跳过操作的时间间隔非常短，最多 9 秒左右。\n- 线上环境难以复现。\n\n## 排查过程\n\n首先拉取 Bug 发生时的日志，会发现被错误地设为成功的步骤的执行目标总数 `Total` 在缓存中被错误地设置为 0，且对应步骤在作业执行开始第一次写入缓存时 `Total` 是正确的，而在执行跳过操作以后第一次被写入缓存时 `Total` 就被设为 0，怀疑是缓存 Bug，但对所有写缓存的操作进行查看和打日志之后，未发现有某处修改了 `Total` 操作或未设置 `Total` 值。\n\n然后尝试复现，在测试了超过 100 次之后，发现可以复现问题的时间似乎与缓存落库定时任务的执行时间有关——例如缓存定时任务每 10 秒运行一次，第一次运行的时间为 yy:yy:y3，那么作业开始执行的时间必须在 xx:xx:x3 到 xx:xx:(x-1)3 之间，且必须在 xx:xx:(x-1)3 之前对某一执行失败的步骤执行跳过操作，否则就无法复现，怀疑是某处对 `Total` 值写了缓存但没有写 DB。\n\n查看步骤跳过的逻辑，发现 `Total` 值只写了缓存，没有写数据库，问题实锤。\n\n排查和修复过程大约花费一天半，几乎全程独立完成。\n\n## 根本原因\n\n在作业执行开始，创建所有步骤的执行历史信息并写入缓存和数据库时，执行主机数量 `Total` 字段只写入了缓存，没有写入数据库，导致所有步骤在数据库中储存的 `Total` 字段被初始化为 `int` 类型的零值（0）。若第一个步骤在 10 秒内执行完毕并点击跳过，由于跳过操作与执行失败这两个事件之间可能相隔很久，为了防止缓存失效，在每次跳过操作时都会直接查询数据库。此时若缓存落库定时任务还没有执行，查询操作就会将这个错误的 `Total: 0` 查询出来并覆盖缓存中正确的值。由于此时 `Succeed`、`Failed`、`Total` 三个字段都等于 0，所以在 `for` 循环中虽然会将作业执行信息发送给执行目标，但执行状态在状态判断逻辑中会被直接判断为成功，进而导致了问题的产生。\n\n当从作业开始执行的时间（设为 `tstart`）到对失败步骤执行跳过的时间（设为 `tend`）小于 `tstart` 之后缓存落库定时任务下一次执行的时间与 `tstart` 的间隔（设为 `ttask`），即 `tend - tstart < ttask` 时，缓存落库定时任务执行过一次之后，由于缓存中正确的 `Total` 值已经被写入数据库，查询操作读取到的就是正确的值，问题也就不会发生了。\n\n而由于线上环境执行的作业由于执行目标比较多、脚本逻辑比较复杂等原因，单个步骤的运行时间一般都大于 10 秒，所以这个步骤在线上环境很难复现。\n\n## 解决方案\n\n1. 在作业执行开始时，将主机数量同时写入数据库和缓存，而不是只写缓存不写数据库。\n2. 对于失败步骤的跳过操作，应直接查缓存，未命中缓存再查询数据库，而不是直接查询数据库。\n3. 提高缓存落库定时任务的执行频率，降低问题发生的概率（当然这并不能从根本上解决问题）。\n\n## 缓存功能的优化方案\n\n1. 不使用 `sync.Map` 而是使用功能更加完备的进程内缓存框架（如 `gcache` 等）。\n2. 可以只缓存与作业状态判断和日志更新相关的小部分数据（如作业 ID、作业的当前状态、重做次数）等，日志则写入消息队列并异步写入数据库（削峰填谷），降低内存占用。\n3. 若考虑多点部署的问题，由于有进程内缓存意味着作业服务是有状态的，所以需要采用一致性哈希等机制将不同的作业 ID 映射到不同的作业服务实例上去，或者采用单独的缓存数据库实现跨进程的缓存（如 `Redis` 等）。\n4. 日志不应该直接写到作业执行历史的某个数组类型的字段（如 `logs`）中，而应该写到专门的日志数据库（如 `ElasticSearch`）中，这不仅仅是因为这些数据库对海量数据的查询操作具有天然的优势，更可以将查询执行历史元数据和查询日志数据的操作分开，提升系统的性能（这一点考虑之后结合 `Metropolitan` 写篇文章讲讲）。\n5. 现有的缓存机制在进程 `panic` 异常退出时会导致未落库的数据（执行中的作业执行历史数据）丢失，需要特别注意在 `recover` 兜底中将数据落库（怀疑之后数次日志丢失 / 作业状态判断不正确的偶现 bug 可能由此引起）。\n\n## 附：缓存读写的业界推荐原则\n\n- 增：先写 DB，再写缓存。\n- 删：先删 DB，再删缓存（并发的情况下可能会读到脏数据，但概率比较小）。\n- 改：先写 DB，再写缓存（同样可能有脏数据问题）。\n- 查：先查缓存，未查到则查 DB，并把查到的数据同步到缓存。\n","tags":["Golang","Cache","Trouble Shooting"],"categories":["Golang","Trouble Shooting"]},{"title":"Go 语言中的 defer","url":"/24a2480bc47a/","content":"\n## defer 的作用\n\n`defer` 是 Go 语言提供的一种延迟执行的机制，可以让函数或者语句在当前函数返回（`panic` 或者 `return`）之后执行，且在 `panic` 之后仍然有效，也就是先 `return` / `panic`，后 `defer`。\n\n`defer` 常见的用法是关闭文件、关闭连接、释放资源等，但也可以用来执行一些在不知道是否会 `panic` 的情况下必须执行的操作。比如在项目中，有一个向服务端汇报执行日志的函数 `SendMsg()`，并且在汇报日志之前需要先做一些处理（例如将日志写到文件中等），在发生丢日志的操作之后发现这些处理逻辑可能产生 `panic`，这时候就可以使用 `defer` 来完成汇报日志的操作，确保无论处理逻辑是否 `panic`，日志都会被正常地上报。\n\n此外，使用 `defer` 配合 `recover` 进行 `panic` 兜底并完成一些“收尾操作”（如关闭连接、关闭文件等）也是很常见的操作（实际上 `recover` 在正常情况下只能配合 `defer` 和匿名函数一起使用，直接执行只会返回 `nil`）。例如：\n\n```go\ndefer func() {\n    if err := recover(); err != nil {\n        // handle error\n    }\n}()\n```\n\n## defer 的执行顺序\n\n`defer` 遵循栈“先进后出”的特点，也就是先定义的 `defer` 后执行。\n\n## defer 的参数\n\n`defer` 的函数参数会在 `defer` 定义时被保存下来，如果是值类型的参数，则 `defer` 实际执行时与 `defer` 定义时一致；如果是引用类型的参数，则不一定一致（因为指针指向的内容可能会被修改）。\n\n也就是说，如果 `defer` 后跟的语句不是闭包（匿名函数），那么在 `defer` 在定义时，参数就已经确定了。如果是闭包，则会在实际执行时根据闭包的上下文来确定。\n\n因此，如果 `defer` 的参数中含有函数调用，那么在 `defer` 定义处需要先执行这个函数以获取 `defer` 函数的参数，之后 `defer` 会正常执行。\n\n有时候我们可以利用这样的特性确保 `defer` 可以做正确的事情，例如一个进程要循环发起多个网络请求并获取响应，我们就可以利用 `defer` 的特点确保所有的响应体都被正确关闭，例如：\n\n```go\nfor _, url := range urls {\n    resp, err := http.Get(url)\n    if err != nil {\n        return err\n    }\n    defer resp.Body.Close()\n}\n```\n\n这里由于 `resp.Body.Close()` 不是闭包，所以在 `defer` 语句处 `resp.Body` 的值已经确定并且被缓存下来，函数返回后实际执行 `defer` 时就不会出现错误了。\n\n## defer 遇上 panic\n\n`defer` 遇上 `panic` 可以分以下几种情况讨论：\n\n1. 如果 `defer` 执行的函数是 `nil`，则会引发 `panic`。\n2. 当函数发生 `panic` 时，会开始遍历 `defer` 链表，按照先进后出的顺序执行 `defer`，此时每个 `defer` 都可以捕获到 `panic`。\n3. 遇到前文提到的 `recover` “兜底”代码时，`panic` 会被捕获，之后所有的 `defer` 都无法捕获 `panic`。\n4. 如果 `defer` 栈中有多个 `panic`，则后面触发的 `panic` 会覆盖掉前面触发的 `panic`，最终仅有最后一个 `panic` 被 `recover` 捕获。\n5. 如果遍历完 `defer` 链表都没有遇上 `recover`，则向 `stderr` 抛出 `panic` 信息，并结束进程。\n\n## 使用 defer 修改函数的返回值\n\n由于 Go 语言中的函数返回值是可以命名的，这些命名的返回值会在函数开始时被初始化为对应类型的零值，作用域为整个函数（包括 `defer`），因此可以使用 `defer` 修改这些返回值。例如：\n\n```go\npackage main\n\nimport \"fmt\"\n\nfunc main() {\n    fmt.Println(doSomething())\n}\n\nfunc doSomething() (retValue int) {\n    defer func() {\n        retValue++\n    }()\n    retValue = 1\n    return\n}\n```\n","tags":["Golang"],"categories":["Golang","Interview"]},{"title":"死锁产生的条件及预防方法","url":"/03ea9547f4e6/","content":"\n## 死锁产生的条件\n\n死锁的产生一共有四个条件：\n\n1. **互斥条件**：一个资源同一段时间内只能为一个进程所用。\n2. **请求和保持条件**：当进程因请求资源而阻塞时，对已经持有的资源保持不放。\n3. **不剥夺条件**：进程获得的资源在使用完毕前不能剥夺，必须由进程主动释放。\n4. **环路等待条件**：在发生死锁的时候必定存在一个进程-资源的环形链。\n\n## 预防死锁的方法\n\n破坏死锁产生的四个条件中的任意一个即可预防死锁的产生。\n\n1. **破坏互斥条件**：把互斥资源变为共享资源，例如共享打印机技术等。\n2. **破坏请求和保持资源**：可以一次性分配所有资源，也可以当某个进程得不到某项资源时，也不给它分配其他资源。\n3. **破坏不剥夺条件**：当某个进程获得了一部分资源但得不到其他资源时，则释放这个进程已经占有的资源。\n4. **破坏环路等待条件**：系统给每类资源赋予一个编号，进程在请求资源时需要按照编号从大到小的方式请求，释放时则相反。\n","tags":["Operating System"],"categories":["Operating System","Interview"]},{"title":"Go 语言中的 make 函数","url":"/bb889d5764e8/","content":"\n## 背景\n\n某一天在阅读公众号时，遇到了这样一道问题：\n\n```go\npackage main\n\nimport \"fmt\"\n\n// 以下代码输出什么？\nfunc main() {\n    m1 := make(map[string]bool, 3)\n    m2 := make(map[string]bool)\n    fmt.Printf(\"%d %d\", len(m1), len(m2))\n    m1[\"a\"] = true\n    m2[\"a\"] = true\n    m1[\"b\"] = true\n    m2[\"b\"] = true\n    fmt.Printf(\"%d %d\", len(m1), len(m2))\n}\n```\n\n答案是 `0 0` 和 `2 2`。\n\n## make() 函数对不同数据类型的作用\n\n这道问题涉及到了关于 `make` 函数的一个知识点：`make` 函数用于初始化某些数据类型时，其参数具有哪些意义？\n首先，`make` 函数可以用于初始化三种数据类型：`slice`、`map`、`channel`。我们比较熟悉的用法一般是用于在初始化 `slice` 的时候指定长度（例如 `make([]int, 10)` 可以初始化一个初始长度为 10 的 `int` 类型切片）和在初始化 `channel` 的时候指定该 `channel` 有无缓冲（例如 `make(chan int, 1)` 可以初始化一个缓冲区大小为 1 的 `int` 类型的 `channel`）。\n但是一般情况下，当 `make` 用于初始化 `map` 时，一般都只有类型这一个参数，例如 `make(map[int]bool)`。那么第二个参数对于 `map` 来说意味着什么呢？\n下面这张表格会告诉我们答案：\n\n| 调用方式                         | 参数类型    | 描述                   |\n| ---------------------------- | ------- | -------------------- |\n| make(T, len)                 | slice   | 初始化一个长度为 len，容量为 cap 的 slice |\n| make(T, len, cap)            | slice   | 初始化一个长度为 len 的 slice            |\n| make(T)                      | map     | 初始化一个 map                          |\n| make(T, cap)                 | map     | 初始化一个容量**大约**为 cap 的 map      |\n| make(T)                      | channel | 初始化一个无缓冲的 channel              |\n| make(T, cap)                 | channel | 初始化一个缓冲区大小为 cap 的 channel    |\n\n因此，上面那道题目的答案就显而易见了：`len` 返回的是 `map` 中键值对的个数，而 `make(map[int]bool, 3)` 初始化了一个长度为 0、容量为 3 的 `map`，其初始长度自然就是 0 了。\n","tags":["Golang"],"categories":["Golang","Interview"]},{"title":"Go 语言中空结构体 struct{} 的作用","url":"/0c4bcffb0ac5/","content":"\n## struct{} 的特性\n\n在 Go 的源代码中，对 `struct{}` 的内存申请都会返回一个固定的内存地址，这说明 `struct{}` 是不占用内存空间的，同样不占用内存空间的还有 `[]struct{}` 等。\n\n对 `struct{}` 调用 `unsafe.Sizeof()` 得到的结果也是 0。\n\n## 配合 map 构造 set\n\nGo 语言是没有自带 `set` 这种数据结构的，但可以使用 `map` 配合 `struct{}` 构造 `set`，比使用 `bool` 每条数据可以节省一个字节的空间：\n\n```go\n// 构造一个 string 类型的 set\nset := map[string]struct{}\n// 向 set 中添加元素\nset[\"a\"] = struct{}{}\n// 判断一个元素（key）是否在 set 中\nif _, ok := set[key]; ok {\n    // 存在\n} else {\n    // 不存在\n}\n// 遍历 set\nfor key := range set {\n    // ...\n}\n```\n\n## 作为方法的 receiver\n\n这种写法比较少见（我在项目中其实还是见过的，只是比较少），但是不会报错：\n\n```go\ntype CalcService struct{}\n\nfunc (s XxxService) Add(a, b int) int {\n    return a + b\n}\n\nfunc (s XxxService) Mul(a, b int) int {\n    return a * b\n}\n```\n\n## 作为 channel 的类型\n\n有的时候我们声明一个 `channel` 并不需要它发送数据，而是进行 `goroutine` 之间的调度、控制 `goroutine` 的个数等，这时候就可以声明一个 `struct{}` 类型的 `channel`。\n\n例如以下是一个使用 `chan struct{}` 进行 `goroutine` 调度，使得两个 `goroutine` 交替输出 1 - 100 的例子（经典面试题）：\n\n```go\npackage main\n\nimport (\n    \"fmt\"\n    \"sync\"\n)\n\nvar (\n    i      = 1\n    chOdd  = make(chan struct{})\n    chEven = make(chan struct{})\n    wg     = sync.WaitGroup{}\n)\n\n// 输出奇数\nfunc odd() {\n    defer wg.Done()\n    for {\n        <-chOdd\n        fmt.Println(\"goroutine1:\", i)\n        i++\n        if i == 100 {\n            chEven <- struct{}{}\n            return\n        }\n        chEven <- struct{}{}\n    }\n}\n\n// 输出偶数\nfunc even() {\n    defer wg.Done()\n    for {\n        <-chEven\n        fmt.Println(\"goroutine2:\", i)\n        i++\n        if i == 101 {\n            return\n        }\n        chOdd <- struct{}{}\n    }\n}\n\nfunc main() {\n    wg.Add(2)\n    go odd()\n    go even()\n    chOdd <- struct{}{}\n    wg.Wait()\n}\n\n```\n","tags":["Golang"],"categories":["Golang","Interview"]},{"title":"【Metropolitan 本纪】01-为什么要重复造轮子？","url":"/c1fcc409ee4c/","content":"\n> 1863 年 1 月，一列由蒸汽机车牵引的木质车厢驶向了伦敦的地下，这宣告着世界上的第一条地铁—— **大都会地铁（Metropolitan Railway）** 就此诞生。\n\n## Metropolitan 是什么？\n\n`Metropolitan` 是一个开源运维自动化平台，其灵感来源于 [Ansible](https://github.com/ansible/ansible) 和 [蓝鲸作业平台](https://github.com/Tencent/bk-job)，支持一键对上万台服务器进行脚本执行、文件分发、定时任务等操作，用户除了使用 `Metropolitan` 提供的这些标准操作之外，还可以根据业务需要定义自己的操作类型（如添加监控、屏蔽监控告警、调用第三方系统等）。`Metropolitan` 还支持将这些操作按步骤编排为一个自动化的任务并通过 `API` 进行调用，实现运维自动化，降低运维成本。\n\n## Metropolitan 的功能？\n\n`Metropolitan` 具有蓝鲸作业平台拥有的几乎所有功能，同时也抛弃了一些不具备通用性的功能（例如和蓝鲸运维体系下其他系统强耦合的功能等），添加了一些新的功能（如自定义的操作类型、服务发现功能等），并大大增强了通用性和可扩展性，且在架构方面更加轻量，更便于小规模业务使用和企业内部根据自己的业务需要进行二次开发。\n\n### 快捷操作\n\n类似于蓝鲸作业平台的“快速执行”功能，对脚本执行、文件分发和某些用户配置的自定义操作类型提供轻量级的、便捷的一次性操作入口。\n\n### 任务编排\n\n类似于蓝鲸作业平台的“任务编排”功能，可以按照用户需要将各项操作（Operation）组装成一个可以单独运行的“任务（Task）”，便于按需调用。\n\n### 任务执行（Metropolitan-Executor）\n\n是一个轻量级的、独立启动的进程，用于执行任务或快捷操作并收集其执行结果，同时还能管理执行产生的日志等信息。\n\n### 定时任务\n\n类似于蓝鲸作业平台的“定时执行”功能，可以实现任务的周期执行和单次定时执行。对于周期执行的任务，可通过图形化的方式或 `Linux` 的 `cron` 表达式指定某个任务的执行时间。\n\n### 通知管理\n\n类似于蓝鲸作业平台的“消息通知”功能，可配置权限与通知事件的对应关系，也可将用户分组并提供按组通知的功能，并在任务执行失败、定时任务执行失败、定时任务开始执行前等需要通知的场景对用户进行通知，同时会保留完整的通知日志，便于用户进行查看。\n\n### 服务发现（Metropolitan-Discovery）\n\n类似于“蓝鲸节点管理平台”，是一个独立启动的进程，可以对 `Agent` 和 `Proxy` 进行管理和查看，也可配置 `Agent` 和 `Proxy` 的发现方式并对其进行健康检查等操作。`Metropolitan-Discovery` 严格来说是一个为 `Metropolitan` 等平台服务的通用组件，所以拥有自己单独的前端界面。\n\n### 基于 RBAC 的用户管理功能\n\n`Metropolitan` 默认提供了基于 `RBAC` 的用户管理功能，可将用户与服务器账号和 `Metropolitan` 的各项功能关联起来，可实现大部分用户的需求，同时也支持用户根据自己的需要接入自己的权限管理系统。\n\n## 架构设计\n\nMetropolitan 的架构图如下：\n\n![Metropolitan 架构图](https://cdn.nlark.com/yuque/0/2022/png/32771015/1668273853403-eddd08ae-6e9c-4c3a-8dac-534cbf586ac6.png#averageHue=%23f7f4f1&clientId=u00a1dc89-6a3b-4&crop=0&crop=0&crop=1&crop=1&from=paste&height=348&id=u34be980e&margin=%5Bobject%20Object%5D&name=image.png&originHeight=522&originWidth=1137&originalType=binary&ratio=1&rotation=0&showTitle=false&size=34263&status=done&style=none&taskId=u2d1031fa-c94a-480d-bb70-666deb227c2&title=&width=758)\n\n`Metropolitan` 是基于 `Go 语言` 和 `TypeScript` 编写的，采用前后端分离的设计方式和端口-适配器模式（六边形架构），具有超强的扩展性，便于企业根据自己的业务需要进行二次开发。\n\n### 前端\n\n基于 `React.js` 和 `Ant Design Pro`，采用 `TypeScript` 开发。\n\n### 后端\n\n使用 `Golang` 开发，整体基于端口-适配器模式（六边形架构）设计，除了 `Metropolitan-Discovery`（由于通用性强而拆分） 和 `Metropolitan-Executor`（由于并发量大、性能要求高而拆分）外，其余部分（统称为 `Metropolitan-Core`）为单体架构，并且是无状态的，可以满足多点部署的需求。`Metropolitan-Discovery`、`Metropolitan-Executor` 和 `Metropolitan-Core` 之间通过 `rpcx`（默认）、`HTTP` 和其他可扩展的方式进行通信。\n\n### 中间件\n\n- `etcd`：提供分布式锁服务的同时作为服务注册与发现中心，使得 `Metropolitan-Core` 与 `Metropolitan-Executor` 之间可以相互进行服务发现。\n- `MongoDB`：`Metropolitan` 的主数据库，保存 `Metropolitan` 所需的几乎全部数据（注：不用 `MySQL` 是为了满足一些结构无法确定的数据的存储需求，如用户自定义的操作类型步骤等）。\n- `Kafka`（可选）：消息队列，传递系统中的心跳检测、任务执行状态切换等 `CloudEvents` 事件等，并传递任务执行过程中产生的日志等信息。\n- `Redis`（可选）：缓存服务，负责缓存任务执行过程中的主机和状态等信息，提高系统的并发能力。\n- `ElasticSearch`：日志数据库，负责保存任务执行中产生的日志信息。\n- `MinIO`：默认的文件存储服务，负责保存用户上传的文件和导出的日志文件等。\n  \n## Metropolitan 的特色功能\n  \n蓝鲸作业平台所具有的那些功能就不再提了，以下是 `Metropolitan` 目前规划的一些“人无我有”的特色功能。\n  \n### 自定义的操作类型（Operation）\n  \n由于 `Metropolitan` 的操作类型 `Operation` 是可扩展的，因此用户可以根据自己的需要来开发可插拔的自定义操作类型——例如调用第三方系统、操作 `K8s`、调用 `GitLab` 等，并将其作为步骤或快捷操作中的执行实体使用，以此来扩展 `Metropolitan` 的能力。\n  \n### 自定义的脚本语言类型（ScriptType）\n  \n`Metropolitan` 默认提供了 `Shell` 和 `Python` 两种脚本语言作为脚本执行的内容，但用户可根据自己的需要来扩展所需的脚本语言，如 `PowerShell` 等（甚至是非脚本语言——如 `Golang` 等），只需要在 `Agent` 上扩展实现对应脚本语言的编译等操作并在 `Agent` 所在的机器上安装对应语言的执行环境即可。\n  \n### 自定义的接入层（API）\n  \n`Metropolitan` 默认提供了 `HTTP` 与 `rpcx` 两种协议的接口，用户可根据需要实现其他协议的接口，如 `gRPC` 等。\n  \n### Client SDK（Metropolitan-Cli）\n  \n默认提供 `Go` 语言的 `Client SDK`，通过 `rpcx` 的方式与 `Metropolitan` 进行交互，便于用户在第三方系统中对接 `Metropolitan`，增强 `Metropolitan` 的自动化能力。\n  \n### 自定义的执行目标来源管理（ExecuteTarget）\n  \n默认通过 `Metropolitan-Discovery` 形成可用的目标服务器列表并通过每个 `Agent` 的 `uuid` 区分不同的执行目标，用户也可以通过二次开发来接入自己的 `CMDB` 等第三方系统实现灵活的执行目标来源管理功能，甚至可以实现按节点、集群等方式批量选择执行目标，只需实现 `GetExecuteTargets()` 方法即可。\n  \n### 系统配置管理（CustomConfig）\n  \n一个可以提供自定义 `JSON` 格式的配置管理的小功能，便于用户在二次开发时将一些必需的数据保存在 `Metropolitan` 中（例如第三方系统的地址等）。\n  \n## 为什么要重复造轮子？\n  \n你可能要问了：既然有了蓝鲸作业平台，那为什么又要重复造轮子呢？除了上述那些特色功能之外，还有以下两个原因：\n  \n### 更轻量\n  \n相比于微服务架构的蓝鲸作业平台，单体架构的 `Metropolitan` 显然更轻量，虽然有 `Metropolitan-Discovery` 和 `Metropolitan-Executor` 这两个独立启动的进程，但是进程数量也比蓝鲸作业平台少得多；同时，`Metropolitan` 是使用 `Golang` 编写的，相比基于 `Java` 和 `Spring Cloud` 的蓝鲸作业平台在运行时占用的资源少得多，部署更加简便，在业务规模较小时也不会造成太大的资源压力。\n  \n### 扩展性更强\n  \n`Metropolitan` 是作为开源项目而不是商业项目诞生的，所以对扩展性和二次开发的能力格外重视。由于六边形架构天然具有更强的可扩展性，架构方面的优势赋予了 `Metropolitan` 强大的扩展能力——几乎什么都可以扩展，可以完美满足用户各种各样的二次开发需求，同时还提供了 `Client SDK`，便于用户将 `Metropolitan` 与现有系统对接。\n  \n### 松耦合\n  \n`Metropolitan` 的定位是一个可以独立使用的项目，它的运行不依赖于其他任何第三方系统，相比蓝鲸作业平台有着更好的兼容性和泛用性。\n\n此外，`Metropolitan` 诞生的意义并不是取代蓝鲸作业平台。蓝鲸作业平台其实只是 `Metropolitan` 的灵感来源之一，而 `Metropolitan` 完全是一个独立的开源项目。\n  \n## 总结\n  \n“我最擅长的事情并不是凭空想出一个不存在的东西，而是优化现有的东西。”\n  \n作为《Metropolitan 本纪》系列的第一篇，这篇文章也标示着 Metropolitan 项目的开始，希望 Metropolitan 可以被更多的人所认可，最终为 SRE 行业贡献出自己的力量。\n","tags":["Metropolitan","Open Source"],"categories":["Metropolitan","Open Source"]},{"title":"Windows PowerShell 开启命令历史提示","url":"/47f7895de753/","content":"\n先看配置效果：\n\n![配置效果](https://cdn.jsdelivr.net/gh/noellemu/pictures/img/20221110133002.png)\n\n## 问题背景\n\n如果你在 Google 上搜索“Windows Powershell 开启命令历史提示”，你会搜到一条这样的命令：`Set-PSReadlineOption -PredictionSource History`，但是这条命令并不是所有人都能直接执行的，例如我，执行这条命令之后会报“Invalid Argument”错误。\n\n出现错误的原因可以参考 [这个 Issue](https://github.com/PowerShell/PSReadLine/issues/3117)，简单来说就是系统自带的 `Set-PSReadLineOption` 版本太低，不支持 `-PredictionSource` 参数，所以我们需要升级 `PSReadLine`。从官方文档中可以查到升级的命令为 `Install-Module PSReadLine -Force -SkipPublisherCheck -AllowPrerelease`，但这条命令也是不可以直接执行的，所以我们需要先升级 `PowerShellGet`，然后再升级 `PSReadLine`。\n\n## 升级 PowerShellGet\n\n用管理员权限打开 `Windows PowerShell`，执行：\n\n```powershell\nInstall-Module -Name PowerShellGet -Force\n```\n\n## 升级 PSReadLine 并配置命令历史提示功能\n\n然后升级 `PSReadLine`，这条命令不需要管理员权限：\n\n```powershell\nInstall-Module PSReadLine -Force -SkipPublisherCheck -AllowPrerelease\n```\n\n升级完成后，编辑配置文件，配置历史提示功能：\n\n```powershell\nvim $Profile\n# 开启命令历史提示，并设置样式为文章开头图片中的列表样式\nSet-PSReadLineOption -ShowToolTips -PredictionSource History\nSet-PSReadLineOption -PredictionViewStyle ListView\n```\n\n最后重新打开 `PowerShell`，此时输入命令就可以看到历史提示了，并且可以使用上下方向键选择想要执行的命令，可以愉快地玩耍了。\n","tags":["Windows"],"categories":["Windows"]},{"title":"go mod 常用技巧总结","url":"/9a024baca258/","content":"\n~~遇事不决 go mod tidy~~\n\n## go mod 指定分支\n\n`go get` git 地址@分支名称\n\n```shell\ngo get -u github.com/xxxx/xxx@branch\n```\n\n## go mod replace 将远程包替换为本地包\n\n将远程包 `github.com/noellemu/api` 替换为本地包（支持绝对路径和相对路径）时，`go.mod` 的写法如下：\n\n```go\nreplace github.com/noellemu/api => ../api\nrequire (\n    github.com/noellemu/api v1.0.0\n)\n```\n\n然后 `go mod tidy` 即可。\n","tags":["Go"],"categories":["Go"]},{"title":"新的个人网站上线了，来聊些杂七杂八的话题吧","url":"/709bf6a98eb1/","content":"\n> Be pragmatic and stay humble.\n> \n> 实事求是，谦虚谨慎。\n\n**注意：此文可能引起某些人的不适。若您在阅读中感受到自己的权益受到了侵犯，请及时退出。另外，你当然有选择抬杠的权利，但你杠就是你对。**\n\n## 新的开始\n\n2022 年 8 月 1 日，我终于签下了人生中第一份劳动合同，这代表着我的人生进入了一个全新的阶段——我终于彻底结束了 4 年压抑得喘不过气的大学生涯，获得了属于自己的自由，4 年来头一次感到自己终于做了一回人。\n\n那么获得自由之后第一件事是什么呢？当然是清理门户，换马甲、换域名、换掉以前的一切……所以就有了现在你们看到的这个网站。\n\n四年前的我如果知道现在的我做的是一份什么样的工作，一定会满腹疑问——毕竟我在跟周围的人说我的工作叫做 SRE 的时候，他们的下一句话不约而同地都是：“SRE 是什么？”，而且彼时的我还对 “Web 安全是一种极其需要天赋的领域，而我却又恰恰没有那种天赋”这个事实一无所知，还妄想着能在安全行业内闯出一番天地。\n\n在被“我做安全是事倍功半的行为”这样的事实教育了之后，我开始寻找新的出路，无意间就接触到了 Java 后端开发。我像是捡到宝了一样，没日没夜地学习 Java、Spring、MySQL 还有各种各样的中间件，不到半年就已经能独立开发一些小型的项目了，也因此获得了人生中第一个实习机会。该说是年少无知还是与其他人跌倒在了同一个地方，我在学习了 Spring Cloud 之后被微服务迷得魂魄出窍，坚信“微服务就是银弹”，于是就开始用 Spring Cloud 开发一个比赛用的项目，还想要部署到 K8s，结果因为 Spring Cloud 这种胖客户端的微服务开发框架与 K8s 天生八字不合，最终也没弄出个所以然来。微服务的优点没感觉到，坑倒是一个不落地踩了个遍，直到现在想起来还是要大喊一句：“微服务把我坑了！”\n\n机缘巧合之下，我了解到了 Service Mesh 和 Istio，也打开了潘多拉的魔盒——云原生 （Cloud Native）。在了解了这种神奇的技术体系之后，我猛然间感到我好像抓住了此生最重要的东西，在了解云原生的过程中也发现 Java 实在是太啰嗦了，不够极简主义，而云原生领域常用的语言 Golang 则更适合我这种极简主义者和实用主义者，于是我果断地抛弃了 Java 并且转向 Golang，用 Golang 完成了很多门课程的实验和大作业，也用 Golang 完成了一个至今仍在运行的外包项目。\n\n但也是在此时，秋招迫在眉睫，我却发现云原生领域的工作如 K8s 开发、Service Mesh 开发等由于专业性太强而几乎完全不校招，于是把目光投向了类似的工作——SRE。在认真了解了 SRE 并拜读了 Google 关于 SRE 的两本著作之后，我发现这其实是一份非常适合我的工作：非常实用主义、成就感强烈、比业务开发更加底层、CRUD 的比重小、符合我个人的技术栈、可以应用新技术……于是我便将 SRE 作为目标岗位之一，最终也成功拿到了 Offer、有了现在的这份工作。\n\n新生活就这样开始了，做着自己最喜欢的工作并能以此谋生，或许是这世界上最幸福的事情之一了吧。\n\n## 关于实用主义\n\n“空谈误国，实干兴邦”，这是我们每个人都无比熟悉的一句话，可是直到现在，我才深刻地体会到这句话的重量。\n\n在耽误了我 4 年时间的那所大学的计算机学院里，实用主义是四等公民，所有的一切都在朝着“实践是技校学生才会去做的事情，我们不能干那种自降身份的事情”、“算法高级，你们所有人都要去做算法”、“做东西就要做炫酷的、没人见过的，对现有事物的改造与优化是愚蠢的行为”这样的方向演进。且不说这些话中饱含着偏见与歧视，对“绝大多数计算机专业的本科毕业生的第一份工作都是软件开发”这样的现状也毫无认知，更透露着一种由愚昧无知带来的傲慢。于是，在这样的大环境下，无数的二极管、键盘侠、人上人一个接一个地涌现出来，明明自己没多少能耐，却总以为自己是世界的中心，殊不知人外有人、山外有山，通用能力和专业能力没怎么培养出来，优越感却已经满级了。连实际工作中每天都会遇到的那些基本的技术问题都回答不出来，却高喊着“学术人高于打工人”，或者以为自己的技术实力世界最强而毫不掩饰对自认为“菜”的那些人的不屑，这样的人 4 年来我遇见了太多太多，对这样的现状也早已习以为常了。\n\n是的，我曾经也是那样的人。我曾经认为自己的技术实力无人能敌，也曾认为培养通用实力是极其耽误时间的事情。但是直到参加工作的那一刻，我才发现通用实力的重要性，也发现脚踏实地的人能在这个绝大多数人都在空谈梦想的时代中获得巨大的红利。说到底，学历不过只是能力的一种罢了，没有学历或许会让一个通用能力十分强大的人错失许多机会，但一个人若只有学历而没有其他任何通用能力，那他在离开象牙塔之后如何在社会上生存都是问题。\n\n对像你我这样的普通人来说，成长其实就是逐步接受现实、接受自己的平凡的过程。小时候，我们每个人都想成为救世主；后来，在成长的过程中，我们渐渐发现连做自己的救世主都很难，更别提改变世界了；最后我们恍然醒悟——人能做到的事情其实很少，我们能做到的对自己最有利的事情就是接受现实、适应现实，然后找到在这种现状下最佳的生存方法。\n\n我曾经也是一名梦想家，整日沉迷于幻想无法自拔，在现实中一遇到什么不如意就立刻逃到幻想的世界中。在现实中我只是沧海中普通得不能再普通的一粟，但在幻想的世界中我却是造物主，掌握着生杀大权，看谁不顺眼就能在幻想的世界中让他永世不得安息。或许你想说“这样不是也挺好的吗”，但是，在上海这座拥有八千多家咖啡馆、有着各种各样的文化、充满了机遇与挑战的城市中的 8 个月（截至本文写作时）的工作和生活经验让我慢慢意识到：幻想除了消耗精神能量外，对自己的生活没有任何好处，它不仅会让你看起来像一个疯癫的傻子、一个另类的自大狂，更会阻碍你去做真正应该做的事情，最终毁掉你的一生。\n\n梦想还是要有的，星空还是要仰望的，可是一步一个脚印地走好脚下的路，才是在这个时代下的我们真正应该做的事情。\n\n所以，成为一名脚踏实地的实用主义者，是我今年最大的愿望。为此，我每天都在与伴随了我 22 年的幻想能力战斗——由于我此前一直用各种各样的借口纵容我的幻想，导致它已经成为了一种我难以控制的本能，与它正面对抗不会有任何好结果，只能通过拼命工作和发展各种各样的爱好（例如读书、数码、咖啡、探店、开源项目、公路旅行、轨道交通等）等方式慢慢夺取它所需要的时间和精神能量等资源并将它饿死。除此之外，别无他法。\n\n因此，我将自己的座右铭定为“Be pragmatic and stay humble”，即“实事求是，谦虚谨慎”，也就是你们在点进这个网站时看到的最醒目的那一句话。同时，我也希望我所写下的文字也能帮到在迷茫中徘徊的你。万事开头难，“说干就干”其实能解决我们遇到的大多数问题。\n\n## 在路上\n\n经常有人认为像我这样的轨道交通迷是一个奇怪的、难以理解的群体。但其实，运转和公路旅行一样，都是一种不以到达某地为目的而是享受“到达”的过程或是“到达”的方式的生活哲学，只不过道路不是公路而是铁路，交通工具不是汽车，而是地铁和火车。\n\n我常常觉得坐在某种交通工具上奔向某个未知的目的地时，总是能想明白很多事情。同样地，在周末坐在路边一家小小的咖啡馆里品味着一杯咖啡时，灵感也总是不断地从脑海中涌现。或许人这一生的某些重大转折点并不是在工作或者学习中产生的，而是偶然间想明白了某些事情或让自己的某些逻辑形成了闭环。\n\n其实人生也是一种像公路旅行或是运转一样在路上前进的过程，区别是我们不知道自己将会去向何处。因此，定下某一阶段的目的地并朝着它前进、享受在路上的过程才是这个过程中最重要的事情。不知道有多少人是想明白了这一点才成为实用主义者的，但我是其中的一员——毕竟，当你乘坐的火车刚刚从某一站开出，距离你的目的地还有好几个小时甚至好几天的时候，最聪明的做法当然是享受坐火车的过程——例如去餐车体验一下有着这趟列车的特色的晚饭，或是在车厢里走走看看不同的旅客都在做什么事情，亦或拿起一本书静静地阅读或看着窗外的风景发呆，而不是思考“怎么还有这么远，为什么火车这么慢，会不会晚点，会不会出事故”等完全脱离现实又消耗自己精神能量的问题。\n\n这一点，是我在 2018 年 8 月于北京开往上海的 1461 次列车上想到的，那次运转或许也是我人生中第一次不以到达为目的的旅行。可惜的是，当时虽然想明白了如此重要的道理，却没有将它纳入自己的逻辑体系中，直到今天，在阅读一本公路旅行相关的书籍时，我才终于回想起了那时的顿悟。\n\n## 这个网站的未来？\n\n谈了这么多现实的事情，是时候仰望一下星空了。\n\n我将会在这个网站记录与技术有关的一切，但又不会让它完全成为一个技术博客——毕竟这个网站的建站的初衷是个人网站而不是技术博客。我会争取做到技术文章和非技术文章在这个网站上各占一半。除了技术文章之外，读书感悟、轨道交通、咖啡、公路旅行、英语学习、翻译、文化等也会是常见的主题。\n\n同时，由于我正在学习英语，这个网站上的所有内容也会慢慢变成中文版和英文版共存的状态，以此来作为英文写作和英文语境的练习。\n\n## 结语\n\n你以为我会说“苦日子要来了”或者“起风了，唯有努力生存”？那你就完全猜错了。我只是刚刚从一个换乘站登上了列车，而列车也刚刚驶离地铁站，正在前往下一个终点站的路上，而我正享受着窗外的风景和在路上的感觉。不信你看，这个网站的配色不就是从上海地铁 1 号线和 18 号线得到的灵感吗？试着切换一下深色模式和浅色模式吧。\n","tags":["Off topic"],"categories":["Off topic"]},{"title":"一文看懂 Web 后端开发","url":"/f46e6cebc106/","content":"\n## Warning\n\n本文写作于 2021 年 3 月，其中有些信息目前可能已经过时，请注意甄别。\n\n## 前言\n\n由于网络上系统地介绍后端开发的文章实在太少，而最近有恰巧有许多同学问我“什么是后端开发？”、“你为什么喜欢后端开发？”、“做后端都需要学什么？”，那么我们就来讲一讲，到底什么才是后端开发。\n\n## 定义\n\n**后端开发**（`Back-End Development`，也称**服务端开发**、**服务器端开发**等）是创建完整可运行的Web应用服务端程序（服务端程序和资源合称为**后端**，即在服务器上运行的、不涉及用户界面的部分）的过程，是Web应用程序开发的一部分。后端开发者使用`Java`、`Golang`等语言及其衍生的各种框架、库和解决方案来实现Web应用程序的核心业务逻辑，并向外提供特定的API，使得Web应用能够高效、安全、稳定地运行。\n\n## 说人话！\n\n好吧，如果你看了定义仍然很懵，那我就用一些非常易于理解的表达形式来说一说“什么是后端开发”。虽然这些表述可能并不严谨或完全正确，但是我相信这样一定能使你明白什么是后端开发。\n\n这里我们拿前端来类比一下，因为我相信绝大多数看到这篇文章的人都已经对“什么是前端开发”、“什么是前端”有一定了解了：\n\n1. 前端就相当于我们的肉体，后端就相当于我们的灵魂和思想；\n2. 前端是如何操作游戏，后端是具体的游戏规则；\n3. 前端是用户能看到的，后端是用户看不到的；\n4. 前端是跑在浏览器上的，后端是跑在服务器上的；\n5. 前端采集用户的输入，后端处理用户的输入；\n6. 前端开发是写代码给用户看，后端开发是写代码给服务器看。\n\n是不是这样一讲就明白了？那我们接着往下看。\n\n## 具体职责\n\n1. **实现Web应用程序的实际业务逻辑。**即：实现Web应用程序的具体功能（如注册、发表和查询信息等）或Web应用程序在服务端执行的具体操作。这是后端开发这项工作的主要内容；\n2. **使用API和创建API。**后端需要向前端提供前端所需的数据，也需要使用第三方API来完成业务逻辑（如完成某个功能需要通过API调用其他应用、在使用框架进行开发时需要使用语言和框架的API、操作数据库时需要使用数据库或ORM框架的API等）。因为在后端开发的过程中经常需要与API打交道，所以有人也把后端开发称为“API开发”，就像有些人将前端称为“GUI开发”一样；\n3. **优化。**在用户量达到一定程度后，就会出现诸如响应慢等各种问题（不理解的话想想你们大学的选课系统）；同时，随着代码行数的增多，许多架构上的缺陷可能也会随之暴露出来，如代码逻辑混乱、模块划分不正确等。此时就需要后端开发人员对Web应用程序进行优化，如重构、分布式部署、优化业务逻辑、单体应用拆分成微服务等；\n4. **架构设计。**虽然一般只有高级的后端开发人员和架构师才需要关注架构问题，但是架构设计是后端开发中非常重要的一环，因为它决定了如何组织代码、某个模块负责解决什么样的问题、系统的扩展性和可维护性如何、业务逻辑如何进行组织等，也会一定程度上影响到业务逻辑的具体实现（比如微服务和单体架构这两种架构下，同一种业务逻辑的实现可能完全不同）。\n\n## 特征\n\n1. 后端是工作在服务器上的，负责通过API向前端或其他系统提供其所需的信息（如数据等）；\n2. 后端开发实际上是开发Web应用中对用户不可见的部分（如核心业务逻辑、数据库等），大多数的后端开发都是不涉及用户界面的（除了在前后端不分离的架构中将前端的静态页面通过模板引擎改造成动态页面时）；\n3. 通常情况下，一个Web应用的绝大多数代码都属于后端代码，因为后端承担了Web应用实际的业务逻辑；\n4. 后端开发的压力通常比前端开发要大，因为后端是Web应用的“灵魂”，它影响着Web应用的方方面面，除了业务逻辑之外还需要考虑安全性、稳定性、可维护性、可扩展性、伸缩性等问题。\n\n## 技术\n\n1. **程序设计语言**。许多语言都可以用于后端开发，比较流行的是`Java`和`Go`。例如我所使用的就是Go语言，也曾经使用过Java。此外，由于后端开发中经常需要和数据库打交道，所以作为后端开发者，还需要懂`SQL`语言（如果使用了`NoSQL`的话，也需要懂`NoSQL`数据库的语言）；\n2. **数据库**。数据库作为一种简单易用的持久化机制，可以让用户的信息不因为断电等故障而丢失，Web应用开发中经常需要用到数据库，甚至许多简单的Web应用本质上都只是“数据库的可视化系统”，也因为绝大多数简单的业务逻辑本质上都只是对数据库的增删改查（即`CRUD`）；\n3. **框架、库和解决方案**。想要高效率地开发Web应用，框架、库和解决方案是必不可少的，比如MVC框架、ORM框架、RPC框架、微服务开发框架、云基础设施（如Service Mesh、容器编排工具等）、运行时环境/容器（如Docker）、消息队列（Message Queue，MQ）、日志收集和分析工具等；这部分有一些框架是可以跨语言通用的，比如`gRPC`（RPC框架）、`Istio`（Service Mesh），也有一些是某种语言专用的，如`Spring Cloud`（微服务开发工具，JVM技术栈专用）、`Gin`（MVC框架，Go语言专用）；\n4. **架构和指导思想**。架构是后端开发中非常重要的一部分，作为一名后端开发者需要了解常见的架构，如三层架构、SOA、微服务架构、六边形架构等，还需要了解常用于后端开发中的指导思想，如设计模式、MVC模式、DDD、CQRS/ES等；\n5. **包管理工具/项目管理工具**。因为后端开发中经常要用到各种框架和库，所以用于管理这些框架和库的管理工具是非常重要的。每一门语言都有自己的包管理工具，如Java的`Maven`，Go语言的`go mod`等；\n6. **基础知识**。不管是前端开发还是后端开发，都需要对操作系统、计算机网络、数据结构等基础知识有一定了解，还需要了解对应语言的编码规范、重构等知识，这可以帮助你理解框架和库，也能帮助你写出更高质量的代码；\n7. **开发方法**。实际上这个也可以说是属于指导思想的一部分，包括CI/CD、敏捷开发、DevOps等；\n8. **版本管理工具**。相信我，几乎没有人能离开这玩意。最常用的是`Git`。\n\n## 误解\n\n有不少人其实对后端开发误解很深，以下是一些常见的误解：\n\n1. 后端开发就是CRUD/后端开发太简单了；\n2. 不同系统的后端面临的问题高度相似；\n3. 后端开发很枯燥；\n4. 后端的逻辑比前端复杂；\n5. 对于后端开发者来说，设计业务逻辑是一件很简单的事情；\n6. 后端开发的工作太单一了/后端不是一个综合的领域；\n\n这些误解有时候会劝退一些有意从事后端开发的同学，我们现在就来澄清一下这些误解：\n\n1. 我不否认很多简单的Web应用确实就是CRUD，但是绝大多数的Web应用都不仅仅是CRUD。至于“太简单了”，能说出这话的人一定没做过后端，或者只做过CRUD，或者是超级大牛。如果不是超级大牛的话，请说这话的人写一个能撑住五万并发的秒杀系统出来，并做压力测试，然后再看看这句话；另外，后端开发是一个非常综合的领域，既有非常抽象的架构和指导思想，又有具体的解决方案和业务逻辑，还涉及到许多计算机底层问题（如多线程、网络、I/O等）。并且，虽然后端技术稳定，但也不至于学了点东西就可以到哪里都通吃，例如，如果你没听说过云原生、微服务、Serverless等新技术的话，那说明你已经很久没有跟上后端技术的发展了；以及，如果你现在还在用JSP，那我敢肯定你一定没有意识到诸如前后端分离之类的新问题；\n2. 这个说法也完全不对。不同的系统所面临的具体问题是完全不同的。先不说对一个具体的需求可能有很多种不同的解决方案（如针对单点登录（Single Sign On，SSO）问题就有长连接（虽然我没见过落地案例）、共享Session、JWT等方案），有时候甚至当你拿到一个需求时，可能连要解决什么问题都搞不清楚，这也就是为什么诸如DDD这样的系统分析方法一直备受关注，且重构也经常在各种规模的Web应用中都引起重视，因为用户需求往往不是那么明确，可能会引导我们做出错误的设计；\n3. 记住，**枯燥的是CRUD，而不是后端**。后端开发的技术含量实际上是非常高的，也非常有意思，充满了未知与挑战。像微服务、云原生、DDD、CQRS/ES、高并发、负载均衡、缓存、消息队列、多线程、微服务监控、Service Mesh等技术，每一项都值得我们去研究，而这些技术中有很多都是在大型Web应用中被频繁使用的，如果你真正了解后端开发的话，是绝无可能说出“后端开发很枯燥”这样的话的。请记住，并不是不涉及界面的工作就一定很枯燥；\n4. 在大多数的系统中是这样的，但是有些Web应用的前端逻辑复杂程度可能不亚于后端，甚至可能还会超过后端，比如像石墨文档这样的多人协作文档系统，还有ProcessOn这样的在线绘图系统，其前端逻辑可能都是非常复杂的；\n5. 参见2。能说出这话的人一定没重构过一个“大泥球”一样的应用，也没设计过一个用户需求非常模糊的系统（比如用户只给了一条需求：做一个CMS（内容管理系统），你觉得简单你可以来试试，然后用它一个月，如果你不是个有经验的后端开发者的话，我相信你一定会被你自己所写的这个系统逼疯，恨不得将它完全重构）；\n6. 参见1和2。如果后端开发还不综合的话，那什么才是综合的呢？\n\n我不否认做一个只会CRUD的后端开发者很简单，但既然对后端开发感兴趣，那我们就要有更高的志向，不能把自己框死在CRUD里。\n\n这里送给各位未来的后端开发者一句话：“**我等采石之人，当心怀大教堂之愿景**”。如果自己一个人完成一个简简单单的CRUD项目，你可以有自己的想法，例如在其中应用DDD和CQRS，或不断地优化它以达到最佳状态；如果迫于工作经验而不得不CRUD，你也可以用业余时间去提升自己的技术，让自己有更光明的未来。\n\n## 什么样的人适合做后端？\n\n说了这么多，那什么样的人才适合做后端开发这份工作呢？\n\n1. **讨厌写用户界面或与用户界面打交道的人**。有很多人是因为讨厌写界面（尤其是CSS这种反人类的东西）才来做后端开发的。这里没有界面，讨厌与用户界面打交道的人不妨尝试一下后端开发；\n2. **细心的人**。后端开发实际上比前端开发更需要细心。就如前文所述，后端是Web应用程序的“灵魂”，后端开发中的许多问题都决定着Web应用的“生死存亡”，尤其是**数据校验**、**多线程/多进程**、**锁**、**异步编程**、**事务/分布式事务**、**与第三方系统的交互**等，这些问题有非常非常多的细节，且既复杂又非常重要，一旦在细节上出现问题（如数据校验不完全或加锁解锁的逻辑出现错误），轻则出现错误的数据或业务逻辑不能正常运行，重则直接导致整个Web应用挂掉或出现安全问题（如数据校验不完全导致的文件上传漏洞、函数使用错误导致的远程命令执行漏洞等）。所以如果你想从事后端开发，那足够细心绝对是一个必要的条件；\n3. **喜欢与机器打交道多于与人打交道的人**。与前端开发是“写代码给人看”的不同，后端开发是“写代码给服务器看”（或者说给前端/第三方系统看）的。虽然这两个说法都不太严谨，但是后端开发更多的就是与服务器打交道（如降低资源使用率、提高Web应用程序的运行效率等等），而不是与人打交道（如提高页面的美观程度、思考用户的使用逻辑和心理等等）；\n4. **想编写实际的业务逻辑的人，或喜欢算法和逻辑的人**。前端的逻辑更多的是交互逻辑，如点击某个按钮应该弹出什么窗口、怎么把数据渲染成用户想要看到的页面等，而后端的逻辑更多的是实际的业务逻辑，如完成某个功能需要怎样做、请求某个API应该返回什么样的数据等。如果你和我一样写前端时因为总是接触不到实际的业务逻辑而感到不爽，那么大后端欢迎你；\n5. **好奇心强、自学能力强且有终身学习的觉悟的人，或者喜欢钻研技术的人，或喜欢充满挑战性的工作的人**。后端看似简单，实际上技术含量是非常高的。就如前面所说，现在的后端可不仅仅是CRUD，而是随着互联网和云计算技术的发展而不断改变，Web应用程序在需求不断变化的过程中功能变得越来越强，架构变得越来越复杂，对性能的考验也越来越严峻，技术含量自然也就越来越高。作为一名后端开发工程师，需要有不断学习新技术的觉悟，还需要有一定的自学能力，因为不是什么技术都有人教你的，在学习和使用最新技术时对着英文文档啃是常有的事；\n6. **对系统架构感兴趣或想要成为架构师的人**。虽然不可否认的是由于前端至今没有“一统天下”的解决方案而使得前端开发人员经常会比后端开发人员更早地接触到架构的部分，但是传统意义上的前端说白了也就是浏览器那“一亩三分地”（前端同学别喷我，这里仅仅说的是传统的Web前端，“大前端”是不算的哈），而后端技术的天花板则是“地球上人类的数量”（接触过高并发的同学看到这句话应该很有感触吧，哈哈），而核心的业务逻辑往往存在于后端，后端的优化压力往往比前端更大，这就使得初级的后端开发者在进行开发时需要对系统的架构有一定了解、高级的后端开发者需要经常思考系统的架构设计的问题，这也使得后端开发者更容易成长为架构师；\n7. **沉得住气的人**。除了有第5条中提到的“后端的技术含量实际上是非常高的”这一原因之外，还有一个原因就是后端并不是“所见即所得”的，经常需要你编写几十甚至几百行代码、做无数复杂的配置才能把Web应用运行起来（注意，是运行，写业务逻辑的话需要更多代码），另一个原因是后端开发的门槛比前端要高——你至少得掌握一门语言和这门语言在后端开发方面的一些框架或库才能开始开发。所以，后端开发者必须要沉得住气，不能因为写几行代码看不到任何效果就想放弃；\n8. **对系统的基础设施（如框架、库和解决方案等）感兴趣的人**。据我所知，许多在云原生方面有深刻造诣的大佬都是从后端开发者成长起来的，许多框架的作者曾经也是后端开发者。如果你碰巧像我一样对框架、库和解决方案（如`Spring Boot`、`Spring Cloud`、`Gin`、`Kubernetes`、`Istio`等）十分感兴趣，那么可以从成为一名后端开发者开始，在编写业务代码的过程中慢慢体会框架的重要性和所用框架的优缺点，以及如何设计一个好的框架。\n\n虽然你并不需要满足以上每一项才能成为一个后端开发工程师，但是如果你发现你满足上面的某一条或某几条，而且你还没有找到自己的方向，那么不妨来尝试一下后端开发。\n\n## 我为什么喜欢后端开发\n\n先简单介绍以下我的经历吧。我从2019年1月开始接触前端开发，于2019年8月正式转向后端开发，并一直从事后端开发至今。我喜欢后端开发的原因，其实很简单：\n\n1. 我反感写界面，痛恨GUI编程，每次一写界面我就想遁地。后端开发不需要考虑界面的问题，这里没有界面，只有API；\n2. 我喜欢写实在的业务逻辑，不想总是隔着个API而“任人摆布”，解决实际问题对我来说简直棒极了；\n3. 我喜欢与机器打交道，可以写一天的代码而不感到无聊，但我不喜欢与人打交道，尤其是面对面交谈非技术问题时总会感到不自然（当然，聊技术我能聊一天都不嫌烦）；\n4. 我想要成为一名架构师，想成就优秀的设计，而后端开发能更多地接触到系统的架构和设计；\n5. 接触到后端开发后，我发现我对这一领域内的绝大多数事物都感兴趣，如云原生、DDD、Service Mesh、系统架构等；\n6. 写前端会让我感到痛苦万分，因为我审美诡异、不擅长思考用户的使用逻辑、不擅长编写交互逻辑，写出来的东西又丑又反人类。而当我开始写后端时，我发现我的思考方式经常和真实的业务逻辑出奇地一致，有时候还能在做项目的过程中发现当前所使用的工具的不足，并且思考如何才能设计得更好；\n7. 做后端开发做了一年左右，我越来越感觉到我喜欢这份工作。\n\n如果你也和我有一样的想法，那么你说不定也非常适合从事后端开发的工作。大后端欢迎你的到来。\n\n## 结语\n\n很多人对后端开发的误解源于缺少一篇系统地介绍后端开发的文章。虽然作为一个仅仅入行一年半（截止到2021年3月）的菜鸟，我对后端开发的理解肯定还有许多不足与偏颇，这篇文章也并不那么“系统”，但我仍希望这篇文章能帮助到其他同学了解后端开发或消除对后端开发的误解，抑或找到自己的方向而走上后端开发这条路。\n\n如果发现文中的错漏之处，欢迎发表评论或联系我进行改正。希望能帮到更多对后端开发感兴趣的同学。\n","tags":["Back-end Development","Tutorial"],"categories":["Back-end Development"]},{"title":"【Testify 列传】01-我想做一个什么样的监控系统？","url":"/2504d68c257c/","content":"\n> **Testify**\n> v. 证明；证实；（尤指出庭）作证；见证（上帝的存在）\n> 作为监控系统，Testify 能证实系统中存在的问题；同时作为我的毕业设计项目 Divino 的改进项目，Testify 可以说是见证了我的成长。\n\n## 为什么要做监控系统？\n\n我的本科毕业设计就做了一个监控系统，名为“Divino”，可惜由于时间紧迫加上不了解监控系统的生态，这个项目十分草率地结束了，开源的计划也泡汤了。\n\n但是随着我对 SRE、运维开发、基础架构的研究不断深入，我发现监控系统其实是运维工具中最不可少的工具之一，并且自己也十分需要一个趁手好用的监控系统。\n\n翻看了市面上的一些企业级监控解决方案之后，我却发现它们其实是给已经很成熟的监控系统（如 `Prometheus`、`VictoriaMetrics` 等）套了一层皮，仅仅是实现了一些提高用户体验等方面的业务需求，并没有触及到监控系统最核心的部分，开发定制能力比较差。并且其中有部分还是商业软件，开源版本没有全部功能。再加上重构 `Divino` 势在必行，那么 `Testify` 的定位就十分明确了——`Testify` 是一个基于 `TSDB` 的极简主义的高可扩展性的监控系统。\n\n## 如何理解“极简主义”？\n\n与 `Metropolitan` 一样，`Testify` 其实仅仅是实现了一些最简单的功能，可以满足中小规模场景下的应用。由于每个公司都有每个公司的业务特点和二次开发能力，因此 `Testify` 应该具有很强的扩展性和二次开发能力，满足不同业务规模下的直接使用和二次开发的需求。\n\n## Testify 的架构和技术栈\n\n`Testify` 采用分布式架构，分为两个模块：`Testify-API` 和 `Testify-Server`。其中 `Testify-API` 是一个无状态的 `RESTful API` 服务，用于管理 `Testify`、查看监控历史数据等；`Testify-Server` 则提供了有状态的告警判断、数据转换等服务，若有多种数据源，则一种 `TSDB` 就对应一种 `Testify-Server`。这样的架构设计是为了考虑到扩展性和性能——毕竟我想让 `Testify` 成为一个能在不同规模的业务场景中都适用的监控系统，高资源消耗的 `Testify-Server` 和低资源消耗的 `Testify-API` 分开也能尽量确保两者不会互相争夺资源。二者间可以直接配置对方的地址，也可以通过服务发现的方式进行动态发现。\n\n`Testify` 同时支持 `Push` 和 `Pull` 两种模式，并且兼容 `Prometheus` 和 `OpenTelemetry`，这样做的目的是为了尽可能地提高 `Testify` 的使用场景，并且让业务能够尽量无缝地迁移到 `Testify`。\n\n前端：\n\n- 前端框架：React\n\n- UI 框架：Ant Design\n\n- 数据可视化框架：D3 或 AntV 或 ECharts 等（未定）\n\n后端：\n\n- Web 框架：Gin\n\n- RPC 框架：RPCX（可定制）\n\n- 数据库：MongoDB（可定制）\n\n- TSDB：InfluxDB（可定制）\n\n## Testify 的特色功能\n\n### 同时支持 Push 和 Pull\n\n同时支持 `Push` 和 `Pull` 两种模式的监控系统可不常见，而同时支持两种模式的好处就是用户可以根据自己的业务场景选择合适的数据采集模式。\n\n### 可以任意更换数据库和 TSDB\n\n`Testify` 在设计时就充分考虑到了扩展性，虽然默认使用 `InfluxDB`，但是用户和项目参与者可以根据自己的需要和实际情况来二次开发，适配其他的 TSDB。\n\n### Client SDK 和自定义的接入层\n\n虽然 `Testify` 默认提供了 `HTTP API`，但在企业内部，监控系统与其他系统之间相互调用也是很常见的需求。为此，`Testify` 与 `Metropolitan` 一样提供了 `Client SDK` 供用户方便地调用 `Testify` 的各项功能，同时 `Testify` 还支持用户自行开发自己的接入方式，如 `gRPC` 等。\n\n### 部署方便\n\n服务端只有两个核心组件的 `Testify` 相比某些微服务架构的监控系统更容易部署，在运行时占用的资源也更小，更利于小规模场景使用。\n\n## 总结\n\n项目地址：[Testify](https://github.com/noellemu/testify)\n\n欢迎大家来 Testify 的仓库逛逛，虽然目前什么都没有，但是以后随着基本功能慢慢成型，代码也会逐渐发布到仓库中，欢迎大家参与 Testify 项目，也希望大家可以给个 Star 或者 Fork，非常感谢～\n","tags":["Open Source","Testify"],"categories":["Testify","Open Source"]}]